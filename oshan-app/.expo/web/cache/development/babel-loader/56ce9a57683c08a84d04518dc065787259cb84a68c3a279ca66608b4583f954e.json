{"ast":null,"code":"import _asyncToGenerator from \"@babel/runtime/helpers/asyncToGenerator\";\nimport _classCallCheck from \"@babel/runtime/helpers/classCallCheck\";\nimport _createClass from \"@babel/runtime/helpers/createClass\";\nimport OpenAI from 'openai';\nvar openai = new OpenAI({\n  baseURL: process.env.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1',\n  apiKey: process.env.OPENROUTER_API_KEY,\n  defaultHeaders: {\n    'HTTP-Referer': 'https://oshan.com',\n    'X-Title': 'Oshan Stock Trading App'\n  }\n});\nexport var LLMService = function () {\n  function LLMService() {\n    _classCallCheck(this, LLMService);\n  }\n  return _createClass(LLMService, [{\n    key: \"sendMessage\",\n    value: (function () {\n      var _sendMessage = _asyncToGenerator(function* (messages) {\n        var model = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'openai/gpt-4o-mini';\n        try {\n          var _response$choices$, _response$choices$$me;\n          var openAIMessages = messages.map(function (msg) {\n            return {\n              role: msg.sender === 'ai' ? 'assistant' : 'user',\n              content: msg.message\n            };\n          });\n          var response = yield openai.chat.completions.create({\n            model: model,\n            messages: openAIMessages,\n            max_tokens: 1000,\n            temperature: 0.7\n          });\n          var message = ((_response$choices$ = response.choices[0]) == null ? void 0 : (_response$choices$$me = _response$choices$.message) == null ? void 0 : _response$choices$$me.content) || 'No response received';\n          return {\n            message: message,\n            usage: response.usage ? {\n              prompt_tokens: response.usage.prompt_tokens,\n              completion_tokens: response.usage.completion_tokens,\n              total_tokens: response.usage.total_tokens\n            } : undefined\n          };\n        } catch (error) {\n          console.error('LLM Service Error:', error);\n          if (error instanceof Error) {\n            if (error.message.includes('API key')) {\n              throw new Error('OpenRouter API key not configured. Please check your .env file.');\n            }\n            if (error.message.includes('rate limit')) {\n              throw new Error('Rate limit exceeded. Please try again later.');\n            }\n          }\n          throw new Error('Failed to get response from LLM service');\n        }\n      });\n      function sendMessage(_x) {\n        return _sendMessage.apply(this, arguments);\n      }\n      return sendMessage;\n    }())\n  }, {\n    key: \"getStockAdvice\",\n    value: (function () {\n      var _getStockAdvice = _asyncToGenerator(function* (question, context) {\n        var systemPrompt = `You are a helpful financial assistant for the Oshan stock trading app. \n    Provide clear, concise responses about stock market topics. \n    Always include relevant disclaimers about financial advice.\n    Focus on educational content rather than specific investment recommendations.`;\n        var messages = [{\n          role: 'system',\n          content: systemPrompt\n        }, {\n          role: 'user',\n          content: `Question: ${question}${context ? `\\n\\nContext: ${JSON.stringify(context)}` : ''}`\n        }];\n        try {\n          var _response$choices$2, _response$choices$2$m;\n          var response = yield openai.chat.completions.create({\n            model: 'openai/gpt-4o-mini',\n            messages: messages,\n            max_tokens: 500,\n            temperature: 0.5\n          });\n          return ((_response$choices$2 = response.choices[0]) == null ? void 0 : (_response$choices$2$m = _response$choices$2.message) == null ? void 0 : _response$choices$2$m.content) || 'Unable to provide advice at this time.';\n        } catch (error) {\n          console.error('Stock advice error:', error);\n          return 'Sorry, I encountered an error while processing your request.';\n        }\n      });\n      function getStockAdvice(_x2, _x3) {\n        return _getStockAdvice.apply(this, arguments);\n      }\n      return getStockAdvice;\n    }())\n  }, {\n    key: \"getAvailableModels\",\n    value: (function () {\n      var _getAvailableModels = _asyncToGenerator(function* () {\n        try {\n          var models = yield openai.models.list();\n          return models.data.map(function (model) {\n            return model.id;\n          });\n        } catch (error) {\n          console.error('Failed to fetch models:', error);\n          return ['openai/gpt-4o-mini', 'openai/gpt-4o', 'anthropic/claude-3.5-sonnet'];\n        }\n      });\n      function getAvailableModels() {\n        return _getAvailableModels.apply(this, arguments);\n      }\n      return getAvailableModels;\n    }())\n  }]);\n}();\nexport var llmService = new LLMService();","map":{"version":3,"names":["OpenAI","openai","baseURL","process","env","OPENROUTER_BASE_URL","apiKey","OPENROUTER_API_KEY","defaultHeaders","LLMService","_classCallCheck","_createClass","key","value","_sendMessage","_asyncToGenerator","messages","model","arguments","length","undefined","_response$choices$","_response$choices$$me","openAIMessages","map","msg","role","sender","content","message","response","chat","completions","create","max_tokens","temperature","choices","usage","prompt_tokens","completion_tokens","total_tokens","error","console","Error","includes","sendMessage","_x","apply","_getStockAdvice","question","context","systemPrompt","JSON","stringify","_response$choices$2","_response$choices$2$m","getStockAdvice","_x2","_x3","_getAvailableModels","models","list","data","id","getAvailableModels","llmService"],"sources":["/Users/akhileshgogikar/Oshan/oshan-app/src/services/llmService.ts"],"sourcesContent":["import OpenAI from 'openai';\nimport { ChatMessage } from '../types/models';\n\n// Configure OpenAI client for OpenRouter\nconst openai = new OpenAI({\n  baseURL: process.env.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1',\n  apiKey: process.env.OPENROUTER_API_KEY,\n  defaultHeaders: {\n    'HTTP-Referer': 'https://oshan.com',\n    'X-Title': 'Oshan Stock Trading App',\n  },\n});\n\nexport interface LLMResponse {\n  message: string;\n  usage?: {\n    prompt_tokens: number;\n    completion_tokens: number;\n    total_tokens: number;\n  };\n}\n\nexport class LLMService {\n  /**\n   * Send a chat message to the LLM and get a response\n   * @param messages - Array of chat messages\n   * @param model - Model to use (default: openai/gpt-4o-mini)\n   * @returns Promise<LLMResponse>\n   */\n  async sendMessage(\n    messages: ChatMessage[],\n    model: string = 'openai/gpt-4o-mini'\n  ): Promise<LLMResponse> {\n    try {\n      // Convert ChatMessage format to OpenAI format\n      const openAIMessages = messages.map(msg => ({\n        role: msg.sender === 'ai' ? 'assistant' : 'user',\n        content: msg.message,\n      })) as OpenAI.Chat.ChatCompletionMessageParam[];\n\n      const response = await openai.chat.completions.create({\n        model,\n        messages: openAIMessages,\n        max_tokens: 1000,\n        temperature: 0.7,\n      });\n\n      const message = response.choices[0]?.message?.content || 'No response received';\n      \n      return {\n        message,\n        usage: response.usage ? {\n          prompt_tokens: response.usage.prompt_tokens,\n          completion_tokens: response.usage.completion_tokens,\n          total_tokens: response.usage.total_tokens,\n        } : undefined,\n      };\n    } catch (error) {\n      console.error('LLM Service Error:', error);\n      \n      if (error instanceof Error) {\n        if (error.message.includes('API key')) {\n          throw new Error('OpenRouter API key not configured. Please check your .env file.');\n        }\n        if (error.message.includes('rate limit')) {\n          throw new Error('Rate limit exceeded. Please try again later.');\n        }\n      }\n      \n      throw new Error('Failed to get response from LLM service');\n    }\n  }\n\n  /**\n   * Get a contextual response for stock-related questions\n   * @param question - User's question about stocks\n   * @param context - Additional context (stock data, market info, etc.)\n   * @returns Promise<string>\n   */\n  async getStockAdvice(question: string, context?: any): Promise<string> {\n    const systemPrompt = `You are a helpful financial assistant for the Oshan stock trading app. \n    Provide clear, concise responses about stock market topics. \n    Always include relevant disclaimers about financial advice.\n    Focus on educational content rather than specific investment recommendations.`;\n\n    const messages = [\n      { role: 'system', content: systemPrompt },\n      { role: 'user', content: `Question: ${question}${context ? `\\n\\nContext: ${JSON.stringify(context)}` : ''}` }\n    ] as OpenAI.Chat.ChatCompletionMessageParam[];\n\n    try {\n      const response = await openai.chat.completions.create({\n        model: 'openai/gpt-4o-mini',\n        messages,\n        max_tokens: 500,\n        temperature: 0.5,\n      });\n\n      return response.choices[0]?.message?.content || 'Unable to provide advice at this time.';\n    } catch (error) {\n      console.error('Stock advice error:', error);\n      return 'Sorry, I encountered an error while processing your request.';\n    }\n  }\n\n  /**\n   * Get available models from OpenRouter\n   * @returns Promise<string[]> - List of available model IDs\n   */\n  async getAvailableModels(): Promise<string[]> {\n    try {\n      const models = await openai.models.list();\n      return models.data.map(model => model.id);\n    } catch (error) {\n      console.error('Failed to fetch models:', error);\n      return ['openai/gpt-4o-mini', 'openai/gpt-4o', 'anthropic/claude-3.5-sonnet'];\n    }\n  }\n}\n\n// Export singleton instance\nexport const llmService = new LLMService();"],"mappings":";;;AAAA,OAAOA,MAAM,MAAM,QAAQ;AAI3B,IAAMC,MAAM,GAAG,IAAID,MAAM,CAAC;EACxBE,OAAO,EAAEC,OAAO,CAACC,GAAG,CAACC,mBAAmB,IAAI,8BAA8B;EAC1EC,MAAM,EAAEH,OAAO,CAACC,GAAG,CAACG,kBAAkB;EACtCC,cAAc,EAAE;IACd,cAAc,EAAE,mBAAmB;IACnC,SAAS,EAAE;EACb;AACF,CAAC,CAAC;AAWF,WAAaC,UAAU;EAAA,SAAAA,WAAA;IAAAC,eAAA,OAAAD,UAAA;EAAA;EAAA,OAAAE,YAAA,CAAAF,UAAA;IAAAG,GAAA;IAAAC,KAAA;MAAA,IAAAC,YAAA,GAAAC,iBAAA,CAOrB,WACEC,QAAuB,EAED;QAAA,IADtBC,KAAa,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,oBAAoB;QAEpC,IAAI;UAAA,IAAAG,kBAAA,EAAAC,qBAAA;UAEF,IAAMC,cAAc,GAAGP,QAAQ,CAACQ,GAAG,CAAC,UAAAC,GAAG;YAAA,OAAK;cAC1CC,IAAI,EAAED,GAAG,CAACE,MAAM,KAAK,IAAI,GAAG,WAAW,GAAG,MAAM;cAChDC,OAAO,EAAEH,GAAG,CAACI;YACf,CAAC;UAAA,CAAC,CAA6C;UAE/C,IAAMC,QAAQ,SAAS7B,MAAM,CAAC8B,IAAI,CAACC,WAAW,CAACC,MAAM,CAAC;YACpDhB,KAAK,EAALA,KAAK;YACLD,QAAQ,EAAEO,cAAc;YACxBW,UAAU,EAAE,IAAI;YAChBC,WAAW,EAAE;UACf,CAAC,CAAC;UAEF,IAAMN,OAAO,GAAG,EAAAR,kBAAA,GAAAS,QAAQ,CAACM,OAAO,CAAC,CAAC,CAAC,sBAAAd,qBAAA,GAAnBD,kBAAA,CAAqBQ,OAAO,qBAA5BP,qBAAA,CAA8BM,OAAO,KAAI,sBAAsB;UAE/E,OAAO;YACLC,OAAO,EAAPA,OAAO;YACPQ,KAAK,EAAEP,QAAQ,CAACO,KAAK,GAAG;cACtBC,aAAa,EAAER,QAAQ,CAACO,KAAK,CAACC,aAAa;cAC3CC,iBAAiB,EAAET,QAAQ,CAACO,KAAK,CAACE,iBAAiB;cACnDC,YAAY,EAAEV,QAAQ,CAACO,KAAK,CAACG;YAC/B,CAAC,GAAGpB;UACN,CAAC;QACH,CAAC,CAAC,OAAOqB,KAAK,EAAE;UACdC,OAAO,CAACD,KAAK,CAAC,oBAAoB,EAAEA,KAAK,CAAC;UAE1C,IAAIA,KAAK,YAAYE,KAAK,EAAE;YAC1B,IAAIF,KAAK,CAACZ,OAAO,CAACe,QAAQ,CAAC,SAAS,CAAC,EAAE;cACrC,MAAM,IAAID,KAAK,CAAC,iEAAiE,CAAC;YACpF;YACA,IAAIF,KAAK,CAACZ,OAAO,CAACe,QAAQ,CAAC,YAAY,CAAC,EAAE;cACxC,MAAM,IAAID,KAAK,CAAC,8CAA8C,CAAC;YACjE;UACF;UAEA,MAAM,IAAIA,KAAK,CAAC,yCAAyC,CAAC;QAC5D;MACF,CAAC;MAAA,SA1CKE,WAAWA,CAAAC,EAAA;QAAA,OAAAhC,YAAA,CAAAiC,KAAA,OAAA7B,SAAA;MAAA;MAAA,OAAX2B,WAAW;IAAA;EAAA;IAAAjC,GAAA;IAAAC,KAAA;MAAA,IAAAmC,eAAA,GAAAjC,iBAAA,CAkDjB,WAAqBkC,QAAgB,EAAEC,OAAa,EAAmB;QACrE,IAAMC,YAAY,GAAG;AACzB;AACA;AACA,kFAAkF;QAE9E,IAAMnC,QAAQ,GAAG,CACf;UAAEU,IAAI,EAAE,QAAQ;UAAEE,OAAO,EAAEuB;QAAa,CAAC,EACzC;UAAEzB,IAAI,EAAE,MAAM;UAAEE,OAAO,EAAE,aAAaqB,QAAQ,GAAGC,OAAO,GAAG,gBAAgBE,IAAI,CAACC,SAAS,CAACH,OAAO,CAAC,EAAE,GAAG,EAAE;QAAG,CAAC,CAClE;QAE7C,IAAI;UAAA,IAAAI,mBAAA,EAAAC,qBAAA;UACF,IAAMzB,QAAQ,SAAS7B,MAAM,CAAC8B,IAAI,CAACC,WAAW,CAACC,MAAM,CAAC;YACpDhB,KAAK,EAAE,oBAAoB;YAC3BD,QAAQ,EAARA,QAAQ;YACRkB,UAAU,EAAE,GAAG;YACfC,WAAW,EAAE;UACf,CAAC,CAAC;UAEF,OAAO,EAAAmB,mBAAA,GAAAxB,QAAQ,CAACM,OAAO,CAAC,CAAC,CAAC,sBAAAmB,qBAAA,GAAnBD,mBAAA,CAAqBzB,OAAO,qBAA5B0B,qBAAA,CAA8B3B,OAAO,KAAI,wCAAwC;QAC1F,CAAC,CAAC,OAAOa,KAAK,EAAE;UACdC,OAAO,CAACD,KAAK,CAAC,qBAAqB,EAAEA,KAAK,CAAC;UAC3C,OAAO,8DAA8D;QACvE;MACF,CAAC;MAAA,SAxBKe,cAAcA,CAAAC,GAAA,EAAAC,GAAA;QAAA,OAAAV,eAAA,CAAAD,KAAA,OAAA7B,SAAA;MAAA;MAAA,OAAdsC,cAAc;IAAA;EAAA;IAAA5C,GAAA;IAAAC,KAAA;MAAA,IAAA8C,mBAAA,GAAA5C,iBAAA,CA8BpB,aAA8C;QAC5C,IAAI;UACF,IAAM6C,MAAM,SAAS3D,MAAM,CAAC2D,MAAM,CAACC,IAAI,CAAC,CAAC;UACzC,OAAOD,MAAM,CAACE,IAAI,CAACtC,GAAG,CAAC,UAAAP,KAAK;YAAA,OAAIA,KAAK,CAAC8C,EAAE;UAAA,EAAC;QAC3C,CAAC,CAAC,OAAOtB,KAAK,EAAE;UACdC,OAAO,CAACD,KAAK,CAAC,yBAAyB,EAAEA,KAAK,CAAC;UAC/C,OAAO,CAAC,oBAAoB,EAAE,eAAe,EAAE,6BAA6B,CAAC;QAC/E;MACF,CAAC;MAAA,SARKuB,kBAAkBA,CAAA;QAAA,OAAAL,mBAAA,CAAAZ,KAAA,OAAA7B,SAAA;MAAA;MAAA,OAAlB8C,kBAAkB;IAAA;EAAA;AAAA;AAY1B,OAAO,IAAMC,UAAU,GAAG,IAAIxD,UAAU,CAAC,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}